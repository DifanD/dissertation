{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install packages"
      ],
      "metadata": {
        "id": "3Gb4r0Yd3fhd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxcTGksJ3Ywn"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install xformers\n",
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install jsonlines\n",
        "! pip install fast_ml --quiet\n",
        "! pip install transformers\n",
        "! pip install nltk\n",
        "! python -m nltk.downloader all\n",
        "! pip install unidecode"
      ],
      "metadata": {
        "id": "2AXzHuTV3inl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unidecode import unidecode\n",
        "import nltk\n",
        "from nltk import word_tokenize, WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import transformers\n",
        "from textblob import TextBlob\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import AutoModel, AutoModelForSequenceClassification,AutoTokenizer,pipeline"
      ],
      "metadata": {
        "id": "sMS4kqXj3lRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and transformation"
      ],
      "metadata": {
        "id": "JdlM2cZ43ovS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "df_total = pd.read_parquet('/content/drive/MyDrive/Dissertation/Data/df.parquet')\n",
        "# One-shot sample\n",
        "df_label_unique_sample = df_total.groupby('label_cat', group_keys=False).apply(lambda df: df.sample(1))\n",
        "# Create label mapping\n",
        "label = list(df_label_unique_sample['label'])\n",
        "id = list(df_label_unique_sample['label_cat'])\n",
        "label_to_id = dict(zip(label,id))\n",
        "id_to_label = dict(zip(id,label))"
      ],
      "metadata": {
        "id": "nCrZFn1z3nL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Benchmark sentence similarity data\n",
        "binary_classification_data = pd.read_excel('/content/drive/MyDrive/Dissertation/Label_Classification JC comments.xlsx')\n",
        "binary_classification_data['Label_text'] = binary_classification_data['Label'].map(id_to_label)"
      ],
      "metadata": {
        "id": "n5nVnSo84y-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into Yes only lists and variables with Yes&No text\n",
        "Label_yes = [20,0,21,25,4,8,10,5,23,19,22,28,27,30]\n",
        "Label_yes_no = [3,6,7,9,18]\n",
        "total_label = list(range(0,31))\n",
        "total_second_stage_label  = Label_yes + Label_yes_no\n",
        "total_first_stage_label  = [i for i in total_label if i not in total_second_stage_label]"
      ],
      "metadata": {
        "id": "g9_vjRSz4zin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define functions"
      ],
      "metadata": {
        "id": "byNnYoEs3zWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import sentence similarity model\n",
        "model_infloat = SentenceTransformer('intfloat/e5-small-v2')"
      ],
      "metadata": {
        "id": "tZoYQ0sA3s4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sent_similarity(model,label_cat, label,text,  target_sent,threshold):\n",
        "  #text_extract['Label_cat'] = text_extract['Label'].map(label_to_id)\n",
        "    # Text from the text extraction output\n",
        "  # Label of this row of extraction\n",
        "  label_extract = label_cat\n",
        "  label_extract_text = label\n",
        "  df = target_sent[target_sent['Label']==label_extract]\n",
        "  # check whether the label belongs to Label_yes only or Label_yes_no\n",
        "  if label_extract in Label_yes:\n",
        "  # Target sentence from the Yes-only label\n",
        "    target_sent_yes = list(df['Sentence (for Yes)'])\n",
        "    text_score = sent_sim_func(model,text,target_sent_yes,label_extract_text)\n",
        "    # Return binary classification over threshold\n",
        "    score = text_score['Score']\n",
        "    Label = text_score['Label']\n",
        "    if score >=threshold:\n",
        "        dic = {'Label':Label, 'Result': 'Yes'}\n",
        "    else:\n",
        "        dic = {'Label':Label, 'Result': 'No'}\n",
        "  else: # Belongs to yes/no label\n",
        "      yes_sent = list(df['Sentence (for Yes)'])\n",
        "      no_sent = list(df['Sentence (for No)'])\n",
        "      clean_no_sent = [x for x in no_sent if str(x) != 'nan']\n",
        "      total_sent = yes_sent + clean_no_sent\n",
        "      text_score = sent_sim_func(model,text,total_sent,label_extract_text)\n",
        "      score = text_score['Score']\n",
        "      Label = text_score['Label']\n",
        "      if score >=threshold:\n",
        "        # Check whther it is a Yes or No score\n",
        "        if text_score['target_text'] in yes_sent:\n",
        "          dic = {'Label':Label, 'Result': 'Yes'}\n",
        "        else:\n",
        "          dic = {'Label':Label, 'Result': 'No'}\n",
        "      else:\n",
        "        dic = {'Label':Label, 'Result': 'None'}\n",
        "  return dic"
      ],
      "metadata": {
        "id": "PbNgyiaB3u1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a general function to find simialrity for labels that exists from the first classification model\n",
        "def sent_sim_func(model,source_sent,target_sent, label):\n",
        "  max_score = []\n",
        "  for x in range(len(source_sent)):\n",
        "    for y in range(len(target_sent)):\n",
        "        embedding_1 = model.encode(source_sent[x], convert_to_tensor=True)\n",
        "        embedding_2 = model.encode(target_sent[y], convert_to_tensor=True)\n",
        "        score = float(util.pytorch_cos_sim(embedding_1, embedding_2)[0][0])\n",
        "        target_text = target_sent[y]\n",
        "        source_text = source_sent[x]\n",
        "        dic = {'Text_extracted':source_text,'target_text':target_text,\n",
        "               'Score':score, 'Label': label}\n",
        "        max_score.append(dic)\n",
        "        y+=1\n",
        "    x+=1\n",
        "  max_score_all = [d.get('Score') for d in max_score]\n",
        "  max_score_index = max_score_all.index(max(max_score_all))\n",
        "  max_score_final = max_score[max_score_index]\n",
        "  return max_score_final"
      ],
      "metadata": {
        "id": "027bc8DP36un"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}