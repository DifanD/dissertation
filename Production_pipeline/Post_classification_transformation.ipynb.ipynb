{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import packages"
      ],
      "metadata": {
        "id": "gMBB4RGl6CFh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGPBD95C52zE"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install xformers\n",
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install jsonlines\n",
        "! pip install fast_ml --quiet\n",
        "! pip install transformers\n",
        "! pip install nltk\n",
        "! python -m nltk.downloader all\n",
        "! pip install unidecode"
      ],
      "metadata": {
        "id": "kwgA_RJx6KYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unidecode import unidecode\n",
        "import nltk\n",
        "from nltk import word_tokenize, WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import tensorflow as tf\n",
        "import transformers\n",
        "from textblob import TextBlob\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import AutoModel, AutoModelForSequenceClassification,AutoTokenizer,pipeline"
      ],
      "metadata": {
        "id": "4LnPyWKB6M40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define functions"
      ],
      "metadata": {
        "id": "JwMlu6_w6PV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function that assist label: premise/use classification (primary key)\n",
        "def open_file_premise(path):\n",
        "  with open(path, encoding = 'utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "    # Remove all \\n only elements\n",
        "    lines = [i for i in lines if i != '\\n']\n",
        "    # Remove all lines that is less than 15 characters which is the new line or section\n",
        "    lines = [i for i in lines if len(i)>10]\n",
        "    # Remove \\n for each elemtn in the text file\n",
        "    lines = [i[:-1] for i in lines]\n",
        "    # Select first 50 lines\n",
        "    lines = lines[:50]\n",
        "  return lines\n",
        "\n",
        "\n",
        "# Find label: premise if the score from text classification is low\n",
        "def find_premise(filepath):\n",
        "  lines = open_file_premise(filepath)\n",
        "  for i in lines:\n",
        "    if (('relating to' in i.lower()) or ('related to' in i.lower())):\n",
        "        anc_index = lines.index(i)\n",
        "        line_extract = lines[anc_index+1:anc_index+3]\n",
        "        break\n",
        "    elif 'lr4' in i.lower():\n",
        "        anc_index = lines.index(i)\n",
        "        line_extract = lines[anc_index+1:anc_index+4]\n",
        "        break\n",
        "    elif 'property known' in i.lower():\n",
        "        anc_index = lines.index(i)\n",
        "        line_extract = lines[anc_index:anc_index+2]\n",
        "        break\n",
        "    elif 'premise' in i.lower():\n",
        "        anc_index = lines.index(i)\n",
        "        line_extract = lines[anc_index:anc_index+2]\n",
        "        break\n",
        "  return line_extract\n",
        "\n",
        "# Find label: use if the score from text classification is low\n",
        "def find_use(filepath):\n",
        "  lines = open_file(filepath)\n",
        "  for i in lines:\n",
        "    if 'permitted use' in i.lower():\n",
        "        anc_index = lines.index(i)\n",
        "        line_extract = lines[anc_index:anc_index+3]\n",
        "        break\n",
        "    elif 'use as' in i.lower():\n",
        "        anc_index = lines.index(i)\n",
        "        line_extract = lines[anc_index:anc_index+3]\n",
        "        break\n",
        "    elif 'purpose other' in i.lower():\n",
        "        anc_index = lines.index(i)\n",
        "        line_extract = lines[anc_index+1:anc_index+3]\n",
        "        break\n",
        "    else:\n",
        "        line_extract = 'None'\n",
        "  return line_extract"
      ],
      "metadata": {
        "id": "BmCROFZK6TLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trimming\n",
        "def remove_list_df(df):\n",
        "  df = df.astype(str)\n",
        "  df = df.applymap(lambda x: x[2:len(x)-2] if len(x)>=15 else x) # Avoid removing 'yes', 'no','others','none' value\n",
        "  # Remove some special characters\n",
        "  remove_character= [\"'\", '\"', '“', '”',':','~','[',']']\n",
        "  for i in remove_character:\n",
        "    df= df.applymap(lambda x: x.replace(i, ''))\n",
        "  return df"
      ],
      "metadata": {
        "id": "rJ3zChw07aYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " Post-output transformation on text data\n",
        "def post_output_transformation(dataframe,filepath_collection):\n",
        "    df_cleaned_trimmed = dataframe.copy()\n",
        "    rent_review_method = []\n",
        "    rent_review_date = []\n",
        "    comm_date = []\n",
        "    rent_comm_date = []\n",
        "    term_period = []\n",
        "    Landlord = []\n",
        "    Tenant = []\n",
        "    Premise = []\n",
        "    Use = []\n",
        "    for rows in range(len(df_cleaned_trimmed)):\n",
        "      # Rent Review method clean\n",
        "      test = []\n",
        "      df_review = df_cleaned_trimmed['Rent_Review_method'][rows]\n",
        "      for i in range(len(df_review)):\n",
        "        text_review_method = df_review[i].lower()\n",
        "        if 'open market' in text_review_method:\n",
        "          test.append('Open Market')\n",
        "        else:\n",
        "          test.append('Other')\n",
        "        i+=1\n",
        "      for i in test:\n",
        "        if 'Open Market' in i:\n",
        "          test = 'Open Market'\n",
        "        else:\n",
        "          test = 'Other'\n",
        "      df_cleaned_trimmed.loc[rows,'Rent_Review_method'] = test\n",
        "      # Rent review date clean\n",
        "      test_1 = []\n",
        "      df_review_date = df_cleaned_trimmed['Remain_review_date'][rows]\n",
        "      for i in range(len(df_review_date)):\n",
        "        text_review_date = df_review_date[i].lower()\n",
        "        if 'review date' in text_review_date:\n",
        "          test_1.append(text_review_date)\n",
        "        i+=1\n",
        "      if test_1 == []:\n",
        "        test_1.append('None')\n",
        "      df_cleaned_trimmed.loc[rows,'Remain_review_date'] = test_1\n",
        "      # Commencement date\n",
        "      test_3 = []\n",
        "      df_review_comm_date = df_cleaned_trimmed['Commence_date'][rows]\n",
        "      for i in range(len(df_review_comm_date)):\n",
        "        text_comm_date = df_review_comm_date[i].lower()\n",
        "        text_review_date_cross = df_review_date[i].lower()\n",
        "        if df_review_comm_date != 'None':\n",
        "          if 'commencement date' in text_comm_date:\n",
        "            test_3.append(text_comm_date)\n",
        "          elif 'commencement date' in text_review_date_cross:\n",
        "            test_3.append(text_review_date_cross)\n",
        "        elif 'commencement date' in text_review_date_cross:\n",
        "          test_3.append(text_review_date_cross)\n",
        "        i+=1\n",
        "      if test_3 == []:\n",
        "        test_3.append('None')\n",
        "      df_cleaned_trimmed.loc[rows,'Commence_date'] = test_3\n",
        "\n",
        "      # Rent commencement date\n",
        "      test_4 = []\n",
        "      df_rent_date = df_cleaned_trimmed['Rent_Commence_date'][rows]\n",
        "      for i in range(len(df_rent_date)):\n",
        "        text_rent_comm_date = df_rent_date[i].lower()\n",
        "        if 'rent commencement' in text_rent_comm_date:\n",
        "          test_4.append(text_rent_comm_date)\n",
        "        i+=1\n",
        "      if test_4 == []:\n",
        "        test_4.append('None')\n",
        "      df_cleaned_trimmed.loc[rows,'Rent_Commence_date'] = test_4\n",
        "\n",
        "      # term_period\n",
        "      test_5 = []\n",
        "      df_term_period = df_cleaned_trimmed['Term_period'][rows]\n",
        "      for i in range(len(df_term_period)):\n",
        "        text_term_period = df_term_period[i].lower()\n",
        "        if (('years from' in text_term_period) or ('years commencing' in text_term_period)):\n",
        "          test_5.append(text_term_period)\n",
        "        i+=1\n",
        "      if test_5 == []:\n",
        "        test_5.append('None')\n",
        "      df_cleaned_trimmed.loc[rows,'Term_period'] = test_5\n",
        "\n",
        "      # Parties\n",
        "      landlord_test = []\n",
        "      tenant_test = []\n",
        "      df_parties = df_cleaned_trimmed['Parties'][rows]\n",
        "      for i in range(len(df_parties)):\n",
        "        text_parties = df_parties[i].lower()\n",
        "        if (('(1)' in text_parties) or ('landlord' in text_parties)):\n",
        "          landlord_test.append(text_parties)\n",
        "        elif (('(2)' in text_parties) or ('tenant' in text_parties)):\n",
        "          tenant_test.append(text_parties)\n",
        "        i+=1\n",
        "      if tenant_test == []:\n",
        "        tenant_test.append('CVS Limited') # CVS Leases\n",
        "      if landlord_test == []:\n",
        "        tenant_test.append('None')\n",
        "      Landlord.append(landlord_test)\n",
        "      Tenant.append(tenant_test)\n",
        "\n",
        "      # Use\n",
        "      use_test = []\n",
        "      df_use = df_cleaned_trimmed['Use'][rows]\n",
        "      for i in range(len(df_use)):\n",
        "        text_use = df_use[i].lower()\n",
        "        if (('permitted use' in text_use) or ('use as' in text_use)):\n",
        "          use_test.append(text_use)\n",
        "        i+=1\n",
        "      if use_test ==  []:\n",
        "        use_test.append(find_use(filepath_collection[rows]))\n",
        "      df_cleaned_trimmed.loc[rows,'Use'] = use_test\n",
        "\n",
        "      # Premise\n",
        "      premise_test = []\n",
        "      df_premise = df_cleaned_trimmed['Premise'][rows]\n",
        "      target_word = ['property known','relating to','premise','related to', 'lr4']\n",
        "      for keyword in target_word:\n",
        "        for i in range(len(df_premise)):\n",
        "          text_premise = df_premise[i].lower()\n",
        "          if keyword in text_premise:\n",
        "            text_premise_append = df_premise[i:i+3]\n",
        "            text_join = ' '.join(text_premise_append)\n",
        "            premise_test.append(text_join)\n",
        "            break\n",
        "          else:\n",
        "            i+=1\n",
        "      premise_test = [*set(premise_test)] # Remove duplicate entry\n",
        "      if premise_test == []:\n",
        "        premise_test.append(find_premise(filepath_collection[rows]))\n",
        "      df_cleaned_trimmed.loc[rows,'Premise'] = premise_test\n",
        "      rows+=1\n",
        "    # Append two columns landlord and tenant, drop original party column\n",
        "    df_cleaned_trimmed['Landlord'] = Landlord\n",
        "    df_cleaned_trimmed['Tenant'] = Tenant\n",
        "    df_cleaned_trimmed.drop('Parties',axis = 1,inplace=True)\n",
        "    # Further trimming\n",
        "    df_cleaned_trimmed = remove_list_df(df_cleaned_trimmed)\n",
        "    return df_cleaned_trimmed"
      ],
      "metadata": {
        "id": "8971r43X7xZ1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}